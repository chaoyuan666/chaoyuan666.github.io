<!DOCTYPE html><html lang="zh-CN" data-theme="light"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no"><title>A Survey on Knowledge Graph Embeddings with Literals： Which model links better Literal-ly? | 超远の杂货铺</title><meta name="keywords" content="综述,KGE,无结构信息表示"><meta name="author" content="ChaoYuan"><meta name="copyright" content="ChaoYuan"><meta name="format-detection" content="telephone=no"><meta name="theme-color" content="#ffffff"><meta name="description" content="KG应用程序的计算和存储成本很高。因此，体现了将高维KG映射到低维空间的表示的必要性，即嵌入空间，保留结构以及关系信息。本文对KG嵌入模型进行了研究，该模型不仅考虑了以KG实体和关系形式所包含的结构化信息，还考虑了文本、数值、图像等文字表示的非结构化信息等。除了对迄今为止提出的用文字生成KG嵌入的方法进行理论分析和比较外，还针对链接预测的一般任务，对相同设置下的不同方法进行了实证评估。">
<meta property="og:type" content="article">
<meta property="og:title" content="A Survey on Knowledge Graph Embeddings with Literals： Which model links better Literal-ly?">
<meta property="og:url" content="http://chaoyuan666.github.io/2022/01/06/blog/%E4%B9%B1%E4%B8%83%E5%85%AB%E7%B3%9F/paper001/index.html">
<meta property="og:site_name" content="超远の杂货铺">
<meta property="og:description" content="KG应用程序的计算和存储成本很高。因此，体现了将高维KG映射到低维空间的表示的必要性，即嵌入空间，保留结构以及关系信息。本文对KG嵌入模型进行了研究，该模型不仅考虑了以KG实体和关系形式所包含的结构化信息，还考虑了文本、数值、图像等文字表示的非结构化信息等。除了对迄今为止提出的用文字生成KG嵌入的方法进行理论分析和比较外，还针对链接预测的一般任务，对相同设置下的不同方法进行了实证评估。">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="https://picsum.photos/id/464/3198/2230">
<meta property="article:published_time" content="2022-01-06T12:39:00.000Z">
<meta property="article:modified_time" content="2022-02-22T14:15:09.318Z">
<meta property="article:author" content="ChaoYuan">
<meta property="article:tag" content="综述">
<meta property="article:tag" content="KGE">
<meta property="article:tag" content="无结构信息表示">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://picsum.photos/id/464/3198/2230"><link rel="shortcut icon" href="/img/000.jpg"><link rel="canonical" href="http://chaoyuan666.github.io/2022/01/06/blog/%E4%B9%B1%E4%B8%83%E5%85%AB%E7%B3%9F/paper001/"><link rel="preconnect" href="//cdn.jsdelivr.net"/><link rel="preconnect" href="//busuanzi.ibruce.info"/><link rel="stylesheet" href="/css/index.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@6/css/all.min.css" media="print" onload="this.media='all'"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fancyapps/ui/dist/fancybox.css" media="print" onload="this.media='all'"><script>const GLOBAL_CONFIG = { 
  root: '/',
  algolia: undefined,
  localSearch: {"path":"/search.xml","preload":false,"languages":{"hits_empty":"找不到您查询的内容：${query}"}},
  translate: undefined,
  noticeOutdate: undefined,
  highlight: {"plugin":"highlighjs","highlightCopy":true,"highlightLang":true,"highlightHeightLimit":false},
  copy: {
    success: '复制成功',
    error: '复制错误',
    noSupport: '浏览器不支持'
  },
  relativeDate: {
    homepage: false,
    post: false
  },
  runtime: '',
  date_suffix: {
    just: '刚刚',
    min: '分钟前',
    hour: '小时前',
    day: '天前',
    month: '个月前'
  },
  copyright: {"limitCount":50,"languages":{"author":"作者: ChaoYuan","link":"链接: ","source":"来源: 超远の杂货铺","info":"著作权归作者所有。商业转载请联系作者获得授权，非商业转载请注明出处。"}},
  lightbox: 'fancybox',
  Snackbar: undefined,
  source: {
    justifiedGallery: {
      js: 'https://cdn.jsdelivr.net/npm/flickr-justified-gallery@2/dist/fjGallery.min.js',
      css: 'https://cdn.jsdelivr.net/npm/flickr-justified-gallery@2/dist/fjGallery.min.css'
    }
  },
  isPhotoFigcaption: false,
  islazyload: false,
  isAnchor: true
}</script><script id="config-diff">var GLOBAL_CONFIG_SITE = {
  title: 'A Survey on Knowledge Graph Embeddings with Literals： Which model links better Literal-ly?',
  isPost: true,
  isHome: false,
  isHighlightShrink: false,
  isToc: true,
  postUpdate: '2022-02-22 14:15:09'
}</script><noscript><style type="text/css">
  #nav {
    opacity: 1
  }
  .justified-gallery img {
    opacity: 1
  }

  #recent-posts time,
  #post-meta time {
    display: inline !important
  }
</style></noscript><script>(win=>{
    win.saveToLocal = {
      set: function setWithExpiry(key, value, ttl) {
        if (ttl === 0) return
        const now = new Date()
        const expiryDay = ttl * 86400000
        const item = {
          value: value,
          expiry: now.getTime() + expiryDay,
        }
        localStorage.setItem(key, JSON.stringify(item))
      },

      get: function getWithExpiry(key) {
        const itemStr = localStorage.getItem(key)

        if (!itemStr) {
          return undefined
        }
        const item = JSON.parse(itemStr)
        const now = new Date()

        if (now.getTime() > item.expiry) {
          localStorage.removeItem(key)
          return undefined
        }
        return item.value
      }
    }
  
    win.getScript = url => new Promise((resolve, reject) => {
      const script = document.createElement('script')
      script.src = url
      script.async = true
      script.onerror = reject
      script.onload = script.onreadystatechange = function() {
        const loadState = this.readyState
        if (loadState && loadState !== 'loaded' && loadState !== 'complete') return
        script.onload = script.onreadystatechange = null
        resolve()
      }
      document.head.appendChild(script)
    })
  
      win.activateDarkMode = function () {
        document.documentElement.setAttribute('data-theme', 'dark')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#0d0d0d')
        }
      }
      win.activateLightMode = function () {
        document.documentElement.setAttribute('data-theme', 'light')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#ffffff')
        }
      }
      const t = saveToLocal.get('theme')
    
          const isDarkMode = window.matchMedia('(prefers-color-scheme: dark)').matches
          const isLightMode = window.matchMedia('(prefers-color-scheme: light)').matches
          const isNotSpecified = window.matchMedia('(prefers-color-scheme: no-preference)').matches
          const hasNoSupport = !isDarkMode && !isLightMode && !isNotSpecified

          if (t === undefined) {
            if (isLightMode) activateLightMode()
            else if (isDarkMode) activateDarkMode()
            else if (isNotSpecified || hasNoSupport) {
              const now = new Date()
              const hour = now.getHours()
              const isNight = hour <= 6 || hour >= 18
              isNight ? activateDarkMode() : activateLightMode()
            }
            window.matchMedia('(prefers-color-scheme: dark)').addListener(function (e) {
              if (saveToLocal.get('theme') === undefined) {
                e.matches ? activateDarkMode() : activateLightMode()
              }
            })
          } else if (t === 'light') activateLightMode()
          else activateDarkMode()
        
      const asideStatus = saveToLocal.get('aside-status')
      if (asideStatus !== undefined) {
        if (asideStatus === 'hide') {
          document.documentElement.classList.add('hide-aside')
        } else {
          document.documentElement.classList.remove('hide-aside')
        }
      }
    
    const detectApple = () => {
      if(/iPad|iPhone|iPod|Macintosh/.test(navigator.userAgent)){
        document.documentElement.classList.add('apple')
      }
    }
    detectApple()
    })(window)</script><meta name="generator" content="Hexo 5.4.2"></head><body><div id="sidebar"><div id="menu-mask"></div><div id="sidebar-menus"><div class="avatar-img is-center"><img src="/img/000.jpg" onerror="onerror=null;src='/img/friend_404.gif'" alt="avatar"/></div><div class="sidebar-site-data site-data is-center"><a href="/archives/"><div class="headline">文章</div><div class="length-num">38</div></a><a href="/tags/"><div class="headline">标签</div><div class="length-num">28</div></a><a href="/categories/"><div class="headline">分类</div><div class="length-num">3</div></a></div><hr/><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> 主页</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fas fa-archive"></i><span> 归档</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> 标签</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> 分类</span></a></div><div class="menus_item"><a class="site-page group" href="javascript:void(0);"><i class="fa-fw fas fa-list"></i><span> 列表</span><i class="fas fa-chevron-down"></i></a><ul class="menus_item_child"><li><a class="site-page child" href="/music/"><i class="fa-fw fas fa-music"></i><span> Music</span></a></li><li><a class="site-page child" href="/movies/"><i class="fa-fw fas fa-video"></i><span> Movie</span></a></li></ul></div><div class="menus_item"><a class="site-page" href="/link/"><i class="fa-fw fas fa-link"></i><span> 链接</span></a></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fas fa-heart"></i><span> 关于</span></a></div></div></div></div><div class="post" id="body-wrap"><header class="post-bg" id="page-header" style="background-image: url('https://picsum.photos/id/464/3198/2230')"><nav id="nav"><span id="blog_name"><a id="site-name" href="/">超远の杂货铺</a></span><div id="menus"><div id="search-button"><a class="site-page social-icon search"><i class="fas fa-search fa-fw"></i><span> 搜索</span></a></div><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> 主页</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fas fa-archive"></i><span> 归档</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> 标签</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> 分类</span></a></div><div class="menus_item"><a class="site-page group" href="javascript:void(0);"><i class="fa-fw fas fa-list"></i><span> 列表</span><i class="fas fa-chevron-down"></i></a><ul class="menus_item_child"><li><a class="site-page child" href="/music/"><i class="fa-fw fas fa-music"></i><span> Music</span></a></li><li><a class="site-page child" href="/movies/"><i class="fa-fw fas fa-video"></i><span> Movie</span></a></li></ul></div><div class="menus_item"><a class="site-page" href="/link/"><i class="fa-fw fas fa-link"></i><span> 链接</span></a></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fas fa-heart"></i><span> 关于</span></a></div></div><div id="toggle-menu"><a class="site-page"><i class="fas fa-bars fa-fw"></i></a></div></div></nav><div id="post-info"><h1 class="post-title">A Survey on Knowledge Graph Embeddings with Literals： Which model links better Literal-ly?</h1><div id="post-meta"><div class="meta-firstline"><span class="post-meta-date"><i class="far fa-calendar-alt fa-fw post-meta-icon"></i><span class="post-meta-label">发表于</span><time class="post-meta-date-created" datetime="2022-01-06T12:39:00.000Z" title="发表于 2022-01-06 12:39:00">2022-01-06</time><span class="post-meta-separator">|</span><i class="fas fa-history fa-fw post-meta-icon"></i><span class="post-meta-label">更新于</span><time class="post-meta-date-updated" datetime="2022-02-22T14:15:09.318Z" title="更新于 2022-02-22 14:15:09">2022-02-22</time></span><span class="post-meta-categories"><span class="post-meta-separator">|</span><i class="fas fa-inbox fa-fw post-meta-icon"></i><a class="post-meta-categories" href="/categories/%E8%AE%BA%E6%96%87/">论文</a></span></div><div class="meta-secondline"><span class="post-meta-separator">|</span><span class="post-meta-pv-cv" id="" data-flag-title="A Survey on Knowledge Graph Embeddings with Literals： Which model links better Literal-ly?"><i class="far fa-eye fa-fw post-meta-icon"></i><span class="post-meta-label">阅读量:</span><span id="busuanzi_value_page_pv"></span></span></div></div></div></header><main class="layout" id="content-inner"><div id="post"><article class="post-content" id="article-container"><p>KG应用程序的计算和存储成本很高。因此，体现了将高维KG映射到低维空间的表示的必要性，即嵌入空间，保留结构以及关系信息。本文对KG嵌入模型进行了研究，该模型不仅考虑了以KG实体和关系形式所包含的<strong>结构化</strong>信息，还考虑了文本、数值、图像等文字表示的<strong>非结构化</strong>信息等。除了对迄今为止提出的用文字生成KG嵌入的方法进行理论分析和比较外，还针对链接预测的一般任务，对相同设置下的不同方法进行了实证评估。</p>
<span id="more"></span>

<h1 id="4-带文字的知识图嵌入"><a href="#4-带文字的知识图嵌入" class="headerlink" title="4. 带文字的知识图嵌入"></a>4. 带文字的知识图嵌入</h1><p>本节研究KG嵌入模型，根据使用的文本类型将文本分为以下不同类别：（i）文本，（ii）数字，（iii）图像，以及（iv）多模态。KG嵌入模型利用至少两种提供补充信息的文字，被认为是多模态。在随后的章节中，将对前面描述的每个类别的模型进行描述，分析它们的相似性和差异，然后讨论潜在的缺点。</p>
<h2 id="4-1-具有文本属性的模型"><a href="#4-1-具有文本属性的模型" class="headerlink" title="4.1 具有文本属性的模型"></a>4.1 具有文本属性的模型</h2><p>在本节中，讨论了七种利用文本文字的KG嵌入模型，即Extended RESCAL[37]、 Jointly(desp)[21]、DKRL[13]、Jointly[22]、SSP[23]、KDCoE[24]和KGloVe with literals[36]。对这些模型的比较进行了详细描述，并总结了它们的缺点。此外，为了显示基于复杂性的模型之间的差异，每个模型的参数数量如表3所示。</p>
<p>CATT [97], textural association [98], open-world extension for KGC [99], EDGE [100], TransW [101].</p>
<h4 id="Extended-RESCAL"><a href="#Extended-RESCAL" class="headerlink" title="Extended RESCAL"></a>Extended RESCAL</h4><p>通过扩展其算法来更有效地处理文字值，并处理伴随张量的稀疏性的缺点，来改进原有的RESCAL方法。在原始的RESCAL方法中，关系数据被建模为大小为n×n×m的三维张量$X$，其中n是实体数，m是关系数。$X_{ijk} =1$ 表示的是第i个实体为主语，第k个关系作为谓词，第j个实体作为宾语的三元组的存在。</p>
<p>如果 $X_{ijk} =0$ ，则表示三元组不存在。提出了一种新的张量分解方法，该方法在$X$上执行。有关更多详细信息，请参阅[37]。如果属性三元组必须以这种方式建模，那么文本将被视为宾语实体，包含文字可能会导致运行时的增量，因为必须分解较大的张量。</p>
<p>与原算法相比，扩展的 RESCAL算法在一个单独的矩阵中处理属性三元组。这个矩阵分解是与三元组的张量因子分解共同完成的。只包含文本文本的属性三元组被编码在实体-属性矩阵$D$中，其中行是实体，列是 &lt; data type relation，value &gt; pairs。如果给定一个具有文本数据类型的三元组，比如 rdfs: label 或 yago: haspreferredmeaning，则通过对 object literal 中的文本进行<strong>标记和截断</strong>来创建一个或多个这样的对。</p>
<p>然后将矩阵$D$分解为$D \approx A V$，$A$ 和 $V$分别作为实体和属性的潜在组成部分表示。尽管这种方法在处理多值文本时有优势，但它<strong>不考虑</strong>文本值的序列。</p>
<p>属性允许我们包含简单的、自动聚合的特征，例如（实体、hasRelation、关系名称），这些特征在某些预测任务中很有用。 </p>
<p>在分解中包含属性的一种天真的方法是为属性添加一个额外的切片 m + 1，并对数据中的属性值应用某种形式的预处理。然后将这个预处理步骤的结果与其 相应的谓词作为新索引 n + 1, . . . , n + l 到 X 的实体模式。此外，对于实体 i 的每个属性值 o，那些条目 $X_{i,m+1,n+j}$将被设置为 1，其中 n+j 对应于 o。 </p>
<p>例如，假设文本数据通过标记化进行预处理，属性 (Albert_Einstein, foaf:name, ‘Albert Einstein’) 将设置这些条目$X_{ijk} =1$，其中 i ≡ Albert_Einstein, k ≡ m + 1 和 j ≡&lt;foaf:name, ‘Albert’&gt;或 j ≡ &lt;foaf:name, ‘Einstein’&gt;<br>$$<br>\min <em>{A, R, V} f</em>{l o s s}(A, R)+f_{r e g}(A, R)+f_{a t t r}(A, V)<br>$$<br>$$<br>f_{a t t r}(A, V)=|D-A V|<em>{F}^{2}+\lambda</em>{V}|V|_{F}^{2}<br>$$</p>
<p>其中，$f_{reg}$是正则化项，这是为了防止模型过度拟合。</p>
<h4 id="Jointly-desp"><a href="#Jointly-desp" class="headerlink" title="Jointly(desp)"></a>Jointly(desp)</h4><p>提出了一种新的将实体和词联合嵌入同一向量空间的方法。在我们的解决方案中，定义了知识和文本的相关概率模型，该模型由三部分组成：<strong>知识模型</strong>、<strong>文本模型</strong>和<strong>对齐模型</strong>。知识模型和文本模型都使用相同的核心方法假设进行事实建模：一个候选事实 (h, r, t) 是基于$\parallel h+r-t\parallel $</p>
<p>唯一的区别是，在知识模型中，关系r是<strong>显式监督</strong>的，目标是拟合事实三元组，而在文本模型中，我们假设在某些文本窗口中出现的任何一对单词h和t都具有一定的关系r，但r是一个<strong>隐藏变量</strong>，目标是拟合出现的单词对。</p>
<p>对齐模型保证了实体和词/短语在同一空间的嵌入，并促使两个模型相互增强。本文介绍了两种对齐机制：利用实体名称和利用维基百科锚点。这种联合嵌入知识和文本的方法可以认为是<strong>半监督</strong>的知识嵌入：知识图提供了对事实的明确监督，而文本语料库提供了更多的“关系-未标记”词对。</p>
<p>一种联合学习KGs嵌入和实体描述文本语料库的方法，即使用对齐模型确保实体、关系和单词在同一向量空间中表示。该方法由三部分组成，即知识模型、文本模型和对齐模型。知识模型用于从KG中获取结构化信息的语义。给定一个三元组&lt;h，r，t&gt;，该模型对三元组的合理性进行了细化，如[67]所示：</p>
<p>我们在知识图中定义事实（h，r，t）的以下条件概率：                      <strong>pTransE</strong></p>
<p>$$<br>\operatorname{Pr}(h \mid r, t)=\frac{\exp {z(\mathbf{h}, \mathbf{r}, \mathbf{t})}}{\sum_{\tilde{h} \in \mathcal{I}} \exp {z(\tilde{\mathbf{h}}, \mathbf{r}, \mathbf{t})}}<br>$$</p>
<p>$$<br>z(\mathbf{h}, \mathbf{r}, \mathbf{t})=b-\frac{1}{2}|\mathbf{h}+\mathbf{r}-\mathbf{t}|^{2}<br>$$</p>
<p>其中，b是指定用于调整刻度以获得更好数值稳定性的偏差常数，b=7是一个明智的选择。</p>
<p>然后，知识模型的损失函数定义如下：</p>
<p>知识模型的目标是<strong>最大化</strong>现有事实三元组的条件可能性<br>$$<br>\begin{array}{r}<br>L_{K}=\sum_{(h, r, t)}[\log \operatorname{Pr}(h \mid r, t)+\log \operatorname{Pr}(t \mid h, r)<br>+\log \operatorname{Pr}(r \mid h, t)]<br>\end{array}<br>$$</p>
<p>文本模型采用了[67]中的相同假设，即如果两个单词出现在同一<strong>上下文</strong>中，则它们之间存在关系。</p>
<p>文本窗口，则这两个单词之间存在rwv关系。也就是说，我们可以说（w，rwv，v）的三元组是一个事实。</p>
<p>基于此假设，文本模型定义了一对单词w和v在文本窗口中同时出现的概率，如下所示：<br>$$<br>\operatorname{Pr}(w \mid v)=\frac{\exp {z(w, v)}}{\sum_{\tilde{w} \in V} \exp {z(\tilde{w}, v)}}<br>$$</p>
<p>$$<br>z({w}, {v})=b-\frac{1}{2}|\mathbf{w}-\mathbf{v}|^{2}<br>$$</p>
<p>$$<br>L_{T}=\sum_{(w, v)} \log \operatorname{Pr}(w \mid v)<br>$$</p>
<p>如果我们只有知识模型和文本模型，那么实体嵌入和单词嵌入将在不同的空间中，它们之间的任何计算都是没有意义的。因此，我们需要将两个空间对齐到同一个空间的机制。本文提出了两种机制：利用维基百科锚和利用实体名称。</p>
<p>第三个组件对齐模型的作用是将实体、关系和单词的嵌入放在同一个向量空间中。该子模型通过使用实体描述来对齐这些嵌入。对于实体e描述中的每个单词w，给定e预测w的条件概率定义为：<br>$$<br>\operatorname{Pr}(w \mid e)=\frac{\exp {z(e, w)}}{\sum_{\tilde{w} \in V} \exp {z(e, \tilde{w})}},<br>$$</p>
<p>$$<br>z({e}, {w})=b-\frac{1}{2}|\mathbf{e}-\mathbf{w}|^{2}<br>$$</p>
<p>其中实体向量e与知识模型中出现的实体向量相同，即实体具有单个统一表示，该表示从结构化KG和实体描述中捕获语义。Pr（e | w）的定义类似。根据等式5中给出的定义，对齐模型的损失函数定义为：<br>$$<br>L_{A}=\sum_{e \in \mathcal{E}} \sum_{w \in D_{e}}[\log \operatorname{Pr}(w \mid e)+\log \operatorname{Pr}(e \mid w)]<br>$$</p>
<p>其中$\varepsilon$和$D_{e}$分别表示实体集合和实体e的描述。</p>
<p>通过采用[67]中的联合嵌入框架，联合的主要损失（desp）定义如下：<br>$$<br>L\left(\left{e_{i}\right},\left{r_{j}\right},\left{w_{l}\right}\right)=L_{K}+L_{T}+L_{A}<br>$$</p>
<h4 id="DKRL"><a href="#DKRL" class="headerlink" title="DKRL"></a>DKRL</h4><p>通过利用实体的描述扩展TransE[11]。对于每个实体e，学习两种向量表示，即基于结构的$e_{s}$和基于描述的$e_{d}$。这两种实体表示同时学习到相同的向量空间中，但<strong>不强制统一</strong>，从而可以表示仅具有描述的新实体。为了实现这一点，给定某个三重&lt;h，r，t&gt;，DKRL模型的能量函数定义为：</p>
<p>$$<br>\begin{aligned}<br>E &amp;=\left|h_{s}+r-t_{s}\right|+\left|h_{d}+r-t_{d}\right|<br>+\left|h_{s}+r-t_{d}\right|+\left|h_{d}+r-t_{s}\right|<br>\end{aligned}<br>$$<br>为了学习基于结构的表示，直接应用TransE方法，将三重关系视为从头实体到尾实体的转换。另一方面，连续字袋（CBOW）和深度卷积神经网络（CNN）模型被用来生成头部和尾部实体的基于描述的表示。以CBOW为例，基于关键词的描述生成短文本，并将其对应的词嵌入求和生成实体嵌入。在CNN模型中，在对描述进行预处理后，提供来自维基百科的预训练词向量作为输入。该模型有五层，在每个卷积层池化后，应用卷积层池化来减小卷积神经网络的参数空间和滤波噪声。最大池应用于第一个池，平均池应用于最后一个池。使用的激活函数是tanh或ReLU。CNN模型比CBOW工作得更好，因为它保留了单词的顺序。</p>
<p>为了训练DKRL，以下基于边距的分数函数被视为目标函数，并使用标准反向传播（使用随机梯度下降（SGD））最小化<br>$$<br>\begin{array}{r}<br>L=\sum_{(h, r, t) \in T} \sum_{\left(h^{\prime}, r^{\prime}, t^{\prime}\right) \in T^{\prime}} \max (\gamma+d(h+r, t)<br>\left.-d\left(h^{\prime}+r^{\prime}, t^{\prime}\right), 0\right)<br>\end{array}<br>$$<br>其中，$ \gamma $&gt;0是边界超参数，d是相异函数，$T’$是一组损坏的三元组。实体的表示可以是基于结构的，也可以是基于描述的。</p>
<h4 id="Jointly"><a href="#Jointly" class="headerlink" title="Jointly"></a>Jointly</h4><p>通过利用实体描述学习KG嵌入。具体来说，它通过将实体的基于结构和基于描述的表示与<strong>选通机制</strong>相结合来学习实体的联合嵌入。<strong>门</strong>用于在基于结构的表示和基于描述的表示之间找到平衡。</p>
<p>对于低频实体，描述将为嵌入提供补充信息，从而较好地解决了知识库中的稀疏性问题。对于某个实体，通过将描述转换为固定长度向量，可以从其描述中对表示进行编码。联合使用不同的文本编码器，如单词包、LSTM和注意力LSTM。给定一个实体，我们注意力LSTM编码器可以根据不同的关系从其文本描述中动态选择最相关的信息。</p>
<p>为了集成两种实体表示，我们使用选通机制来确定联合表示在多大程度上依赖于结构或文本</p>
<p>对于实体$e$，其联合表示$e$是其基于结构的表示 ($e_{s}$) 和基于描述的表示 ($e_{d}$) 之间的线性插值，其定义为：<br>$$<br>\mathbf{e}=g_{e} \odot \mathbf{e}<em>{\mathbf{s}}+\left(1-g</em>{e}\right) \odot \mathbf{e}<em>{\mathbf{d}}<br>$$<br>$\odot $是元素级乘法，$g</em>{e}$是平衡两个信息源（结构和文本）的门。</p>
<p>实体描述使用单词包、LSTM或注意LSTM（ALSTM）编码器进行编码，以便为相应实体生成基于文本的表示。另一方面，为了更好地建模基于结构的嵌入，可以使用任何现有的KG嵌入模型（如TransE）对实体和关系进行预训练。联合的评分功能受TransE的启发，定义如下：</p>
<p>$$<br>\begin{array}{c}<br>f\left(h, r, t ; d_{h}, d_{t}\right)=|\left(\mathbf{g}<em>{h} \odot \mathbf{h}</em>{s}+\left(1-\mathbf{g}<em>{h}\right)\right. \left.\odot \mathbf{h}</em>{d}\right)+r-\left(\mathbf{g}<em>{t} \odot \mathbf{h}</em>{t}+\left(1-\mathbf{g}<em>{t}\right) \odot \mathbf{t}</em>{d}\right) |<em>{2}^{2}<br>\end{array}<br>$$<br>其中，$h</em>{s}$、$h_{d}$和$g_{h}$分别是头部实体的基于结构的嵌入、基于描述的嵌入和gate，而$t_{s}$、$t_{d}$和$g_{t}$分别是尾部实体的基于结构的嵌入、基于描述的嵌入和gate。<br>$$<br>\begin{array}{c}<br>J(\Theta)=\sum_{(h, r, t) \in \mathcal{D}} \sum_{(\hat{h}, \hat{r}, \hat{t}) \in \hat{\mathcal{D}}} \max (0, \gamma- f(h, r, t)+f(\hat{h}, \hat{r}, \hat{t}))+\eta|\Theta|_{2}^{2}<br>\end{array}<br>$$</p>
<h4 id="SSP"><a href="#SSP" class="headerlink" title="SSP"></a>SSP</h4><p>SSP (语义空间投影)  [23] 是从结构化/符号三元组和文本描述中学习的联合嵌入模型。但仍有一个问题需要解决，即弱相关建模问题，现有模型很难表征文本和三元组之间的<strong>强相关性</strong>。</p>
<p>在DKRL中，对于三元组，尽可能将头部实体的嵌入向量转换为尾部实体的嵌入向量，然后将文本和实体的向量<strong>串联</strong>为最终的嵌入向量。而在“联合”模型中，作者试图生成相应实体和文本的连贯嵌入。DKRL和“联合”都应用了一阶约束，这些约束在捕获文本和三元组的相关性方面很弱。值得注意的是，三重嵌入始终是主要过程，文本描述必须与三重嵌入交互才能更好地嵌入。只有这样，<strong>语义效应</strong>才能产生更多的感觉。因此，我们通过将三重嵌入投射到语义子空间（如<strong>超平面</strong>）来关注更强的语义交互，如图2所示。在数学上，采用二次约束对强相关性进行建模，从而使嵌入拓扑具有足够的语义学特异性。</p>
<p>与DKRL和联合（Desp）不同，在DKRL和联合（Desp）中，一阶约束在捕获文本描述和符号三元组的相关性方面较弱，SSP遵循三元嵌入始终被视为主要过程的原则，文本描述必须与三元组相互作用学习更好的表示。</p>
<p>因此，采用二次约束将三重嵌入投影到超平面等语义子空间以允许强相关性。</p>
<p><img src="https://pic.imgdb.cn/item/6214efcd2ab3f51d91ad3dda.jpg" alt="image-20220108094305573"></p>
<p>SSP应用以下评分功能：<br>$$<br>f_{r}(h, t)=-\lambda\left|\mathbf{e}-\mathbf{s}^{T} \mathbf{e s}\right|<em>{2}^{2}+|\mathbf{e}|</em>{2}^{2}<br>$$</p>
<p>$$<br>\mathbf{e} \doteq \mathbf{h}+\mathbf{r}-\mathbf{t}<br>$$</p>
<p>由于语义向量的每个分量都指示主题的相关级别，因此我们建议语义组合应采用加法形式:<br>$$<br>\mathbf{s} \doteq \frac{\mathbf{s}<em>{\mathbf{h}}+\mathbf{s}</em>{\mathbf{t}}}{\left|\mathbf{s}<em>{\mathbf{h}}+\mathbf{s}</em>{\mathbf{t}}\right|}<br>$$</p>
<p>其中，标准化用于生成法向量。注意，λ是一个合适的超参数，h和t分别是基于头和尾实体的结构（符号三元组）嵌入，$s_{h}$和$s_{t}$分别是从头和尾实体的文本描述生成的语义向量。</p>
<p>通过文本语义，我们的模型可以<strong>增强辨别能力</strong>。具体地说，通过在相应语义超平面上的投影测量等长损失向量，从而对损失进行合理划分。例如，关于《约翰·鲍威尔》对哪部电影有贡献的问题，有两个候选实体，即真实答案“功夫熊猫”和否定答案“终结者拯救”。如果没有文本语义，就很难进行区分，因此，TransE计算的损失分别为8.1和8.0，这导致了一个艰难的决定。深入到结构语义中，我们发现，“约翰·鲍威尔”与“动画电影”的主题非常相关，后者与“功夫熊猫”的主题相匹配，而与另一个主题不相关。基于这一事实，查询和真实答案都存在于“动画电影”指导的超平面中，而查询和否定答案并不同时出现在相应的关联语义超平面中。因此，真实答案的预计损失可能远小于虚假答案。具体来说，我们模型中的损失分别为8.5和10.8，这足以进行区分。</p>
<p>因此，存在一个重要的限制，即三元组中的实体应嵌入由相关文本语义组成的语义空间中。这种限制被实现为二次形式，以描述文本和三元组之间的<strong>强相关性</strong>，换句话说，与两个信息源交互。</p>
<p>SSE采用非负矩阵分解（NMF）主题模型为实体（$s_{h}$和$s_{t}$）生成基于描述的语义向量，即将每个实体描述视为文档，并将文档的主题分布视为对应实体的表示。</p>
<p>SSP为培训提供两种不同的设置，称为Std和JOINT。在Std中，使用预先训练好的主题模型和NMF来获得基于描述的语义向量。这些基于描述的向量在训练期间是固定的，但其他参数是优化的。另一方面，在JOINT设置中，主题模型也与KG嵌入同时学习，而不是使用固定的预训练向量。</p>
<h4 id="KDCoE"><a href="#KDCoE" class="headerlink" title="KDCoE"></a>KDCoE</h4><p>通过基于利用实体描述的嵌入方法创建新的<strong>语言间链接</strong>（ILLs），重点关注<strong>多语言KG</strong>实体之间的一致性。该模型使用<strong>弱对齐</strong>多语言KG进行<strong>半监督跨语言</strong>学习。它迭代地执行多语言KG嵌入模型（KGEM）和多语言实体描述嵌入模型（DEM）的联合训练，以便每个模型交替提出新的IL。KGEM由两个部分组成，即知识模型和对齐模型，用于基于KGs（非定语三元组）的结构化信息学习嵌入。给定一组语言$\mathcal{L}$，对每种语言$L\in \mathcal{L}$使用单独的$k_{1}$维嵌入空间$\mathbb{R} ^{k_{1}}<em>{L} $来表示$R</em>{L}$和实体$E_{L}$的对应关系。为了学习$R_{L}$和$E_{L}$的嵌入，知识模型采用了TransE，从而以铰链损耗为目标函数。另一方面，对齐模型采用了一种基于线性变换的技术，该技术在跨语言推理的情况下性能最佳。该技术采用以下目标函数：<br>$$<br>S_{A}=\sum_{\left(e, e^{\prime}\right) \in I\left(L_{i}, L_{j}\right)}\left|M_{i j} \mathbf{e}-\mathbf{e}^{\prime}\right|<em>{2}<br>$$<br>其中$I\left(L</em>{i}, L_{j}\right)$是语言$L_{i}$和$L_{j}$之间的ILLs，$M_{ij}$是$k_{1}$×$k_{1}$矩阵，是从$L_{i}$到$L_{j}$的实体向量的线性变换。设$S_{K}$为知识模型使用的铰链损失函数，KGEM模型则最小化$S_{KG}=S_{K}+\alpha S_{A}$，其中α为正超参数。对于DEM模型，使用注意选通递归单元编码器（AGRU）对多语言实体描述进行编码。DEM采用多语词嵌入技术，从词级获取多语实体描述的语义信息。这两个模型，即KGEM和DEM，迭代地共同训练，以便每个模型交替地提出一个新的ILL。</p>
<h4 id="KGloVe-with-literals"><a href="#KGloVe-with-literals" class="headerlink" title="KGloVe with literals"></a>KGloVe with literals</h4><p>是在KG嵌入方法中结合实体描述的实验性尝试。该实验在DBpedia上进行，将实体的摘要和注释作为它们的描述。主要目标是从文本描述中提取命名实体，并针对文本中的每个实体，用实体本身替换表示实体的单词，然后将其相邻的单词和实体作为上下文。该方法的工作原理是独立创建两个共生矩阵，然后在最后合并它们，以便执行联合嵌入。第一个矩阵是使用与KGloVe[68]中相同的技术生成的，即在（加权）图上执行个性化PageRank（PPR），然后进行手套[69]方法中使用的相同优化。</p>
<p>手套遵循一种分布的语义观点，认为词语在上下文中的意义，这基本上依赖于“意义相似的词语出现在相似的上下文中”的假设–也就是说，意义可以从大量文本中单词的上下文（即周围的单词）中获得。</p>
<p>GloVe</p>
<p>最近的学习单词向量空间表示的方法已经成功地使用向量算法捕获细粒度语义和句法规则，但是这些规则的起源仍然是不透明的。我们分析并明确了这些规则在词向量中出现所需的模型属性。结果是一个新的全局对数双线性回归模型，它结合了文献中两个主要模型族的优点：全局矩阵分解和局部上下文窗口方法。我们的模型通过只对单词共现矩阵中的非零元素进行训练，而不是对整个稀疏矩阵或大型语料库中的单个上下文窗口进行训练，有效地利用了统计信息。该模型生成了一个具有有意义子结构的向量空间，在最近的一项单词类比任务中，该模型的性能达到了75%。它在相似性任务和命名实体识别方面也优于相关模型。</p>
<p>词向量学习的适当起点应该是共现概率的比率，而不是概率本身。</p>
<p>注意到Pik/Pjk的比率取决于三个词i、j和k，最一般的模型采用<br>$$<br>F\left(w_{i}, w_{j}, \tilde{w}<em>{k}\right)=\frac{P</em>{i k}}{P_{j k}}<br>$$<br>w字向量 w- 上下文词向量</p>
<p>KGloVe</p>
<p>向量空间嵌入在数据挖掘和机器学习任务中使用RDF数据时表现良好。现有的方法，如RDF2Vec，使用局部信息，即，它们依赖于为RDF图中的节点生成的局部序列。对于单词嵌入，已经提出了全局技术，如手套，作为替代方案。在本文中，我们展示了如何将全局嵌入的思想转化为RDF嵌入，并表明其结果与传统的局部技术（如RDF2Vec）具有竞争力。</p>
<p>是在KG嵌入方法中结合实体描述的实验性尝试。该实验在DBpedia上进行，将实体的摘要和注释作为它们的描述。主要目标是从文本描述中提取命名实体，并针对文本中的每个实体，用实体本身替换表示实体的单词，然后将其相邻的单词和实体作为上下文。该方法的工作原理是独立创建两个共生矩阵，然后在最后合并它们，以便执行联合嵌入。第一个矩阵是使用与KGloVe[68]中相同的技术生成的，即在（加权）图上执行个性化PageRank（PPR），然后进行手套[69]方法中使用的相同优化。为了创建第二个矩阵，使用KG的实体和谓词列表作为输入，对实体描述文本执行命名实体识别（NER）任务。NER步骤采用了一种简单的精确字符串匹配技术，这会导致许多缺点，例如由于具有相同语义的不同关键字而缺少实体。所有与任何实体标签不匹配的英语单词都将添加到实体谓词列表中。然后使用entitypredicate和单词列表作为输入，将文本的手套共现应用于修改后的文本（即DBpedia摘要和注释）。最后，将两个共现矩阵相加，以创建一个统一的矩阵。该方法已在分类和回归任务上进行了评估，结果表明，对于所使用的大多数分类器，除支持向量机外，该方法并没有给KGloVe带来显著的改进。然而，通过大量实验，可以通过参数调整来改进该方法。</p>
<p>总结</p>
<p>这些模型之间的基本区别在于利用文本文本文本中给出的信息并将其与基于结构的表示相结合的方法。与基于文本的嵌入模型相比，KDCoE的一个主要优点是它考虑了多语言KG中的描述。</p>
<p>此外，DKRL和KDCoE嵌入模型都被设计用于处理新实体，它们在KG中只有属性三元组。联合（Desp）将KG嵌入和单词嵌入在单词层面上对齐，这可能会导致在短语或句子层面上丢失一些语义信息。联合应用门控机制，允许自动在结构信息和文本信息之间找到平衡。它还使用LSTM编码器，该编码器使模型能够根据不同的关系从实体的文本描述中为实体选择最相关的信息。与DKRL和Joinly  (DESP) 不同，SSP通过将三重嵌入投影到语义子空间(例如超平面)上来描述实体描述和结构化三元组之间的更强相关性，如上文所述。</p>
<p>所提出的文本文本文本方法的另一个常见缺点是，它们主要关注描述，这是一个较长的自然语言文本，因此，其他类型的文本文本，例如名称、标签、标题等没有得到广泛考虑。此外，比较这些方法的另一种方法是查看它们的模型复杂性。表3显示了这些模型在参数数量方面的复杂性。</p>
<h4 id="CATT"><a href="#CATT" class="headerlink" title="CATT"></a>CATT</h4><p>通过知识图谱和实体描述之间的<strong>完全注意力</strong>来补全知识图谱</p>
<p>考虑到不同的实体在不同的三元组中具有不同的语义，提出了一种在完全注意（CATT）机制下，基于三元组学习知识图中实体描述信息的方法。这样，实体在不同的三元组中具有相应语义的不同表示。对于实体描述信息的编码，我们使用了三种深度学习方法，包括CNN、Bi LSTM和Transformer。实验结果表明，该方法在实体预测和关系预测两方面的性能都有显著提高。</p>
<p>在不同的三元组中，同一实体表达了不同的方面，关系的含义和属性，而仅通过KGs的结构信息无法区分差异。例如，三重 (Donald Trump，presidentOf，the United States) 中的实体 “唐纳德·特朗普” (Donald Trump，presidentOf，the United States) 强调实体的属性是 “的职业”。同时，在另一个三元组(Donald Trump，fatherOf，Ivanka Trump)  强调属性为 “的父母”。</p>
<p>贡献：</p>
<ol>
<li>为了学习文本语料库的表示，我们使用 CNN、Bi-LSTM 和 Transformer 三种深度学习方法对实体描述进行编码并分析结果。</li>
<li>我们提出了一个完整的注意力机制，强调同一实体在不同的三元组中具有不同方面的信息。由于引入了实体描述，它减少了噪音。</li>
<li>只有实体描述，链接预测已经达到了state-ofart的结果</li>
</ol>
<h5 id="KG表示"><a href="#KG表示" class="headerlink" title="KG表示"></a>KG表示</h5><p>$$<br>\boldsymbol{f}(\boldsymbol{h}, \boldsymbol{r}, \boldsymbol{t})=|\boldsymbol{h}+\boldsymbol{r}-\boldsymbol{t}|<em>{L</em>{1} / L_{2}}<br>$$</p>
<h5 id="实体描述"><a href="#实体描述" class="headerlink" title="实体描述"></a>实体描述</h5><p>编码得到的文本表示独立于KG的实体，限制了实体描述的表达能力。事实上，实体描述的感兴趣内容在不同的实体对中会有所不同。例如，“唐纳德特朗普”的描述与“总统”匹配时应强调与职业相关的描述性信息，而与“沃顿商学院”匹配时应强调与教育相关的描述性信息。</p>
<p>相同的实体具有在不同三元组中有不同的文本表示。<br>$$<br>\alpha_{i}=\operatorname{softmax}\left(h_{s} \cdot z_{i}\right)=\frac{\exp \left(h_{s} \cdot z_{i}\right)}{\sum_{j=1}^{n} \exp \left(h_{s} \cdot z_{j}\right)}\<br>\beta_{i}=\operatorname{softmax}\left(t_{s} \cdot z_{i}\right)=\frac{\exp \left(t_{s} \cdot z_{i}\right)}{\sum_{j=1}^{n} \exp \left(t_{s} \cdot z_{j}\right)}\<br>\gamma_{i}=\operatorname{softmax}\left(r \cdot z_{i}\right)=\frac{\exp \left(r \cdot z_{i}\right)}{\sum_{j=1}^{n} \exp \left(r \cdot z_{j}\right)}<br>$$<br>反映了头部实体、尾实体、关系在其描述中对每个文本表示的关注程度。<br>$$<br>a_{i}=\alpha_{i}+\beta_{i}+\gamma_{i}\<br>\widehat{\boldsymbol{a}<em>{\boldsymbol{\imath}}}=\frac{a</em>{\boldsymbol{i}}}{\sum_{\boldsymbol{j}=\mathbf{1}}^{\boldsymbol{i}} a_{\boldsymbol{j}}}\<br>\boldsymbol{d}=\sum_{j=1}^{m} \widehat{a_{j}} z_{j}<br>$$<br>那么$d$表示对应的的描述向量</p>
<h5 id="对齐模型"><a href="#对齐模型" class="headerlink" title="对齐模型"></a>对齐模型</h5><p>$$<br>\min <em>{\boldsymbol{\theta}} \sum</em>{(h, r, t) \in T} \sum_{\left(h^{\prime}, r^{\prime}, t^{\prime}\right) \in T^{\prime}} \max \left(\mathbf{0}, \boldsymbol{\delta}-\boldsymbol{f}(\boldsymbol{h}, \boldsymbol{r}, \boldsymbol{t})+\boldsymbol{f}\left(\boldsymbol{h}^{\prime}, \boldsymbol{r}^{\prime}, \boldsymbol{t}^{\prime}\right)\right)\<br>\boldsymbol{f}(\boldsymbol{h}, \boldsymbol{r}, \boldsymbol{t})=\boldsymbol{f}<em>{s s}(\boldsymbol{h}, \boldsymbol{r}, \boldsymbol{t})+\boldsymbol{f}</em>{s d}(\boldsymbol{h}, \boldsymbol{r}, \boldsymbol{t})+\boldsymbol{f}<em>{d s}(\boldsymbol{h}, \boldsymbol{r}, \boldsymbol{t})+\boldsymbol{f}</em>{d \boldsymbol{d}}(\boldsymbol{h}, \boldsymbol{r}, \boldsymbol{t})\<br>\boldsymbol{f}<em>{d s}(\boldsymbol{h}, \boldsymbol{r}, \boldsymbol{t})=-\left|\boldsymbol{h}</em>{d}+\boldsymbol{r}-\boldsymbol{t}<em>{s}\right|</em>{L_{1} / L_{2}} \<br>\boldsymbol{f}<em>{s d}(\boldsymbol{h}, \boldsymbol{r}, \boldsymbol{t})=-\left|\boldsymbol{h}</em>{s}+\boldsymbol{r}-\boldsymbol{t}<em>{d}\right|</em>{L_{1} / L_{2}}\<br>\boldsymbol{f}<em>{s s}(\boldsymbol{h}, \boldsymbol{r}, \boldsymbol{t}) =-\left|\boldsymbol{h}</em>{s}+\boldsymbol{r}-\boldsymbol{t}<em>{s}\right|</em>{L_{1} / L_{2}} \<br>\boldsymbol{f}<em>{d d}(\boldsymbol{h}, \boldsymbol{r}, \boldsymbol{t}) =-\left|\boldsymbol{h}</em>{\boldsymbol{d}}+\boldsymbol{r}-\boldsymbol{t}<em>{\boldsymbol{d}}\right|</em>{L_{1} / L_{2}}<br>$$</p>
<h4 id="textural-association"><a href="#textural-association" class="headerlink" title="textural association"></a>textural association</h4><p>要充分优化嵌入，还必须考虑更广泛可用的信息来源，例如文本。本文描述了一种<strong>无监督</strong>方法，通过使用关联词的嵌入来增强实体嵌入来合并文本信息。该方法不会修改知识图嵌入的优化目标，这允许它与现有的嵌入模型集成。考虑了两种不同形式的文本数据，针对每种情况提出了不同的嵌入增强。在第一种情况下，每个实体都有一个描述它的关联文本文档。在第二种情况下，文本文档不可用，而是实体作为非结构化文本片段语料库中的单词或短语出现。我们考虑一个非结构化语料库，它不直接链接到任何实体，但包含在任意位置的实体提及。</p>
<p>实验表明，当应用于许多不同的知识图嵌入模型时，这两种方法都可以改进链接预测任务。</p>
<p>在这项工作中，我们考虑了两种不同形式的文本数据，它们可能与知识图中的实体相关联，并提出了可以使用每种类型的数据增强现有知识图嵌入模型的方法。</p>
<p>我们首先考虑文本描述或文档与每个实体相关联的情况。例如，许多现实世界的实体和单词的描述可以很容易地从维基百科或字典中获得。我们为此场景提出了一个模型，该模型使用特定于关系的词向量加权平均值来表示特定实体。</p>
<h5 id="WWV"><a href="#WWV" class="headerlink" title="WWV"></a>WWV</h5><p>$$<br>\mathbf{e}<em>{i}=\frac{\mathbf{A}</em>{i} \mathbf{W}}{\left|\mathbf{A}<em>{i}\right|</em>{1}}\<br>\mathbf{e}<em>{i}^{\left(r</em>{j}\right)}=\frac{\left(\mathbf{A}<em>{i} \odot \mathbf{B}</em>{j}\right) \mathbf{W}}{\left|\mathbf{A}<em>{i} \odot \mathbf{B}</em>{j}\right|_{1}}<br>$$</p>
<p>例如transE<br>$$<br>f\left(e_{s}, r_{p}, e_{o}\right)=-\left|\mathbf{e}<em>{s}^{\left(r</em>{p}\right)}-\mathbf{r}<em>{p}+\mathbf{e}</em>{o}^{\left(r_{p}\right)}\right|_{1}<br>$$</p>
<h5 id="PE-WWV"><a href="#PE-WWV" class="headerlink" title="PE-WWV"></a>PE-WWV</h5><p>$$<br>B_{i j}=\frac{\exp \left(\mathbf{P}<em>{i} \mathbf{W}</em>{j}^{T}\right)}{\sum_{k=1}^{n_{w}} \exp \left(\mathbf{P}<em>{i} \mathbf{W}</em>{k}^{T}\right)}\<br>\mathbf{e}<em>{i}^{\left(r</em>{j}\right)}=\frac{\sum_{w_{k} \in \operatorname{text}\left(e_{i}\right)} A_{i j} \exp \left(\mathbf{P}<em>{j} \mathbf{W}</em>{k}^{T}\right) \mathbf{W}<em>{k}}{\sum</em>{w_{k} \in \operatorname{text}\left(e_{i}\right)} A_{i j} \exp \left(\mathbf{P}<em>{j} \mathbf{W}</em>{k}^{T}\right)}<br>$$</p>
<p>在第二种情况下，知识图中的实体没有关联的文档，而是在语料库中的各个点被提及。对于这种情况，我们提出了一个不同的模型，它首先通过在语料库上训练词嵌入 [Mikolov et al., 2013] 来获得实体的表示。生成的词向量基于实体名称与文本中其他词的共现提供实体的语义描述。然后将这些向量与实体嵌入相结合以增强表示。</p>
<h5 id="FeatureSum"><a href="#FeatureSum" class="headerlink" title="FeatureSum"></a>FeatureSum</h5><p>$$<br>\hat{\mathbf{e}}<em>{i}=\mathbf{e}</em>{i}+\mathbf{w}_{i} \mathbf{M}<br>$$</p>
<p>结论：</p>
<p>本文讨论了两种新方法，用于使用来自文本数据的信息来增强知识图中的实体嵌入。第一种方法将实体向量表示为与每个实体相关联的单词的直接函数，并且适用于以实体描述形式提供文本数据的任何时候。第二种方法在文本文档上训练 word2vec 算法，并将它为实体名称学习的特征添加到原始实体特征向量中。经验结果表明，如果文本数据具有足够高的质量，那么与没有文本的嵌入和合并文本的替代方法相比，这两种方法都可以提高许多不同嵌入模型的链接预测准确性。</p>
<h4 id="open-world-extension-for-KGC"><a href="#open-world-extension-for-KGC" class="headerlink" title="open-world extension for KGC"></a>open-world extension for KGC</h4><p>提出了对基于嵌入的知识图完成模型的新扩展，使它们能够执行<strong>开放世界链接预测</strong>，即根据文本描述预测训练中未见过的实体的事实。我们的模型结合了从知识图谱中学习的常规链接预测模型和从文本语料库中学习的词嵌入。在独立训练之后，我们学习了一种转换，将实体名称和描述的嵌入映射到基于图的嵌入空间。<br>在包括 FB20k、DBPedia50k 和我们的新数据集 FB15k-237-OWE 在内的多个数据集的实验中，我们展示了具有竞争力的结果。特别是，即使文本描述稀缺，我们的方法也能利用完整的知识图结构，不需要对图和文本进行联合训练，并且可以应用于任何基于嵌入的链接预测模型，例如 TransE、ComplEx 和 DistMult<br>$$<br>\operatorname{score}(h, r, t)=\phi\left(u_{h}, u_{r}, u_{t}\right)<br>$$</p>
<p>$$<br>v_{h}:=\Psi^{a g g}\left(v_{w_{1}}, v_{w_{2}}, \ldots, v_{w_{n}}\right)<br>$$</p>
<p>$$<br>\Psi^{\operatorname{map}}\left(v_{h}\right) \approx u_{h}<br>$$</p>
<p>$$<br>\operatorname{score}(h, r, t)=\phi\left(\Psi^{\operatorname{map}}\left(v_{h}\right), u_{r}, u_{t}\right)<br>$$</p>
<h4 id="EDGE"><a href="#EDGE" class="headerlink" title="EDGE"></a>EDGE</h4><p>在本文中，提出了实体描述引导嵌入（EDGE），这是一种利用实体描述的语义引导学习知识图表示的新方法。 EDGE 使嵌入模型能够同时学习 1) 在给定 KG 中直接观察到的知识三元组，以及 2) 具有关于这些实体的丰富语义信息的实体描述。在学习过程中，EDGE对实体描述的语义进行编码，以增强对知识图嵌入的学习，并结合学习到的KG嵌入，将其对应的词嵌入约束在实体描述中。<br>通过这个交互过程，实体描述的语义可以更好地转移到学习的 KG 嵌入中。我们评估 EDGE 在 Freebase 和 WordNet 上的链接预测和实体分类。实验结果表明：1）通过注入实体描述，EDGE 在最先进的基线上实现了显着且一致的改进； 2）与之前研究的那些一次性注入方案相比，交互式引导策略最大化了实体描述在 KG 嵌入中的效用，并且确实实现了更好的性能。</p>
<h5 id="基本嵌入模型"><a href="#基本嵌入模型" class="headerlink" title="基本嵌入模型"></a>基本嵌入模型</h5><p>transE<br>$$<br>E\left(e_{h}, r, e_{t}\right)=\left|\boldsymbol{e}<em>{\boldsymbol{h}}+\boldsymbol{r}-\boldsymbol{e}</em>{\boldsymbol{t}}\right|<br>$$</p>
<h5 id="分层-BiLSTM-最大池化编码器"><a href="#分层-BiLSTM-最大池化编码器" class="headerlink" title="分层 BiLSTM 最大池化编码器"></a>分层 BiLSTM 最大池化编码器</h5><p>先经过Word2vec预训练词向量处理，</p>
<p>句子中的词序列$\left(w_{1}, \ldots, w_{T}\right)$，对应的输出$\left(h_{1}, \ldots, h_{T}\right)$，其中$h_{t}$是两者之间的串联<br>$$<br>h_{t}=\left[\overrightarrow{h_{t}}, \overleftarrow{h_{t}}\right]\<br>\overrightarrow{h_{t}}=\overrightarrow{L S T M}<em>{t}\left(w</em>{1}, \ldots w_{T}\right)\<br>\overleftarrow{h_{t}}=\overleftarrow{L S T M_{t}}\left(w_{1}, \ldots w_{T}\right)<br>$$<br>最大池化层用于在隐藏单元$\left(h_{1}, \ldots, h_{T}\right)$上产生每个维度的最大值，同时它也具有与$h_{t}$相同的维度。将分层的BiLSTM 最大池作为我们的编码器，以提高神经网络对每个单词进行<strong>编码</strong>和<strong>记忆</strong>的能力。具体来说，我们假设每一层神经网络都可以重新读取输入描述。</p>
<p>我们将三层 BiLSTM 最大池化网络作为我们的层次结构。我们用上一层的最终隐藏和单元状态初始化第二和第三层 BiLSTM 层的初始隐藏状态和单元状态。此外，通过每个 BiLSTM 层之后的最大池化，我们在隐藏单元的每个维度上取最大值。最终的输出嵌入$e_{d}$是所有三个最大池化向量$u_{1},u_{2},u_{3}$的平均值。</p>
<h5 id="知识约束方法"><a href="#知识约束方法" class="headerlink" title="知识约束方法"></a>知识约束方法</h5><p>为了从实体描述中实现这种交互式引导，我们采用约束模型并使用欧几里得距离来定义一对向量之间的距离。</p>
<p>具体来说，我们希望描述中与实体相关的词嵌入$w_{i}$对学习的实体嵌入 $e_{i}$及其邻居$e_{j}$是封闭的。$\forall j$在给定的 KG 关系$(e_{i},e_{j})\in R$;以下优化问题变为<br>$$<br>\min \sum_{i=1}^{|V|}\left[\alpha_{i}\left|w_{i}-e_{i}\right|^{2}+\sum_{\left(e_{i}, e_{j}\right) \in R} \beta_{i j}\left|w_{i}-e_{j}\right|^{2}\right]<br>$$<br>其中 V 是单词的词汇量，α 和 β 是用于控制相对强度的可调整值。这个优化问题是凸的，它的解可以通过求解一个线性方程组来找到。为了改进词嵌入$w_{i}$，更新过程是<br>$$<br>\left(\alpha_{i}+\sum_{\left(e_{i}, e_{j}\right) \in R} \beta_{i j}\right) w_{i}-\alpha_{i} e_{i}-\sum_{\left(e_{i}, e_{j}\right) \in R} \beta_{i j} e_{j}=0<br>$$<br>那么更新后的词嵌入$w_{i}$是<br>$$<br>w_{i}=\frac{\sum_{\left(e_{i}, e_{j}\right) \in R} \beta_{i j} e_{j}+\alpha_{i} e_{i}}{\sum_{\left(e_{j}, e_{j}\right) \in R} \beta_{i j}+\alpha_{i}}<br>$$<br>上面描述的这种改造方法是模块化的，这意味着它可以应用于从任何模型获得的词嵌入。</p>
<h5 id="训练"><a href="#训练" class="headerlink" title="训练"></a>训练</h5><p>由于结构和实体描述都可以为 KG 嵌入学习提供有用且丰富的语义信息，因此我们将它们整合到一个联合表示中。对于实体 e，我们提出了两种嵌入来表示它，包括$e^{s}$，e 的结构嵌入$e^{d}$，来自实体描述的编码表示。为了结合这两种信息，我们在结合实体的结构表示和描述中的实体表示时应用了门控机制。通过$e^{s}$和$e^{d}$的组合得到最终的联合实体嵌入 e。<br>$$<br>e=g_{e} \odot \mathrm{e}^{s}+\left(1-g_{e}\right) \odot e^{d}<br>$$<br>考虑到每个维度包含的信息之间的差异，我们也将 ge 设置为向量。为了约束 ge 的每个元素的值在 [0, 1] 中，我们通过逻辑 sigmoid 函数计算门<br>$$<br>\mathrm{g}<em>{e}=\sigma\left(\tilde{\mathrm{g}</em>{e}}\right)<br>$$<br>其中$\tilde{\mathrm{g}<em>{e}} \in \mathbb{R}^{d}$是一个实值向量，一旦$\tilde{\mathrm{g}</em>{e}}$被学习，它就保持不变。我们用于训练的目标函数是最小化以下得分函数<br>$$<br>\begin{array}{}<br>L=\sum_{\left(e_{h}, r, e_{t}\right) \in O} \sum_{\left(e_{h}^{\prime}, r^{\prime}, e_{t}^{\prime}\right) \in O^{\prime}} \max \left(\gamma+d\left(\boldsymbol{e}<em>{\boldsymbol{h}}+\boldsymbol{r}, \boldsymbol{e}</em>{\boldsymbol{t}}\right)\right.\left.-d\left(\boldsymbol{e}<em>{\boldsymbol{h}}^{\prime}+\boldsymbol{r}^{\prime}, \boldsymbol{e}</em>{\boldsymbol{t}}^{\prime}\right), 0\right)\<br>\begin{aligned}<br>O^{\prime}=\left{\left(e_{h}^{\prime}, r, e_{t}\right) \mid e_{h}^{\prime} \in E\right} \cup &amp;\left{\left(e_{h}, r, e_{t}^{\prime}\right) \mid e_{t}^{\prime} \in E\right}\cup\left{\left(e_{h}, r^{\prime}, e_{t}\right) \mid r^{\prime} \in R\right}<br>\end{aligned}<br>\end{array}<br>$$</p>
<h4 id="TransW"><a href="#TransW" class="headerlink" title="TransW"></a>TransW</h4><p>本文提出了一种称为 TransW 的新方法，旨在通过使用<strong>词嵌入组合知识图嵌入</strong>来超越当前的工作。鉴于实体或关系包含一个或多个单词（经常）这一事实，学习从单词嵌入空间到知识嵌入空间的映射函数是明智的，它显示了如何使用人类单词构建实体。更重要的是，使用词嵌入组合知识嵌入使得处理新出现的新事实（新实体或关系）成为可能。使用三个公共数据集(WN11,FB13,FB15K)的实验结果显示了所提出的 TransW 的一致性和优异性能。</p>
<p>在 TransW 中，每个实体或关系都以词嵌入的线性组合形式表示。对于一个三元组$(h,r,t)$及其嵌入$(\boldsymbol{h},\boldsymbol{r},\boldsymbol{t})$，假设 h, r 和 t 中的词数分别为 n, p 和 m，则$(h,r,t)$可以是用他们的词嵌入表示：<br>$$<br>\begin{aligned}<br>\mathbf{h} &amp;=\sum_{i=0}^{\mathrm{n}} \mathbf{h}<em>{i} \otimes \mathbf{w}</em>{h i}+\mathbf{b}<em>{h} \<br>\mathbf{t} &amp;=\sum</em>{i=0}^{\mathrm{m}} \mathbf{t}<em>{i} \otimes \mathbf{w}</em>{t i}+\mathbf{b}<em>{t} \<br>\mathbf{r} &amp;=\sum</em>{i=0}^{\mathrm{p}} \mathbf{r}<em>{i} \otimes \mathbf{w}</em>{r i}+\mathbf{b}<em>{r}<br>\end{aligned}<br>$$<br>其中$h</em>{i},t_{i},r_{i} \in \Bbb W$分别是对应的h, r, t中第i个词的词嵌入，⊗表示哈达玛(Hadamard)积，$w_{hi},w_{ti},w_{ri}$,是h, r和t的第i个连接向量，$b_{h},b_{t},b_{r} \in \Bbb R^k$ 分别是实体 h 和 t 以及关系 r 的偏置参数。<br>$$<br>L=\sum_{\xi \in \Delta} \sum_{\xi^{\prime} \in \Delta^{\prime}}\left[\gamma+f_{r}\left(\xi^{\prime}\right)-f_{r}(\xi)\right]_{+}<br>$$</p>
<h2 id="4-2-具有数字文本的模型"><a href="#4-2-具有数字文本的模型" class="headerlink" title="4.2 具有数字文本的模型"></a>4.2 具有数字文本的模型</h2></article><div class="post-copyright"><div class="post-copyright__author"><span class="post-copyright-meta">文章作者: </span><span class="post-copyright-info"><a href="http://chaoyuan666.github.io">ChaoYuan</a></span></div><div class="post-copyright__type"><span class="post-copyright-meta">文章链接: </span><span class="post-copyright-info"><a href="http://chaoyuan666.github.io/2022/01/06/blog/%E4%B9%B1%E4%B8%83%E5%85%AB%E7%B3%9F/paper001/">http://chaoyuan666.github.io/2022/01/06/blog/%E4%B9%B1%E4%B8%83%E5%85%AB%E7%B3%9F/paper001/</a></span></div><div class="post-copyright__notice"><span class="post-copyright-meta">版权声明: </span><span class="post-copyright-info">本博客所有文章除特别声明外，均采用 <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" target="_blank">CC BY-NC-SA 4.0</a> 许可协议。转载请注明来自 <a href="http://chaoyuan666.github.io" target="_blank">超远の杂货铺</a>！</span></div></div><div class="tag_share"><div class="post-meta__tag-list"><a class="post-meta__tags" href="/tags/%E7%BB%BC%E8%BF%B0/">综述</a><a class="post-meta__tags" href="/tags/KGE/">KGE</a><a class="post-meta__tags" href="/tags/%E6%97%A0%E7%BB%93%E6%9E%84%E4%BF%A1%E6%81%AF%E8%A1%A8%E7%A4%BA/">无结构信息表示</a></div><div class="post_share"><div class="social-share" data-image="https://picsum.photos/id/464/3198/2230" data-sites="facebook,twitter,wechat,weibo,qq"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/social-share.js/dist/css/share.min.css" media="print" onload="this.media='all'"><script src="https://cdn.jsdelivr.net/gh/overtrue/share.js@master/dist/js/social-share.min.js" defer></script></div></div><nav class="pagination-post" id="pagination"><div class="prev-post pull-left"><a href="/2022/01/18/blog/%E4%B9%B1%E4%B8%83%E5%85%AB%E7%B3%9F/web/"><img class="prev-cover" src="https://picsum.photos/id/525/5184/3456" onerror="onerror=null;src='/img/404.jpg'" alt="cover of previous post"><div class="pagination-info"><div class="label">上一篇</div><div class="prev_info">常用Web</div></div></a></div><div class="next-post pull-right"><a href="/2022/01/04/blog/%E4%B9%B1%E4%B8%83%E5%85%AB%E7%B3%9F/First/"><img class="next-cover" src="https://picsum.photos/id/464/3198/2230" onerror="onerror=null;src='/img/404.jpg'" alt="cover of next post"><div class="pagination-info"><div class="label">下一篇</div><div class="next_info">Markdown 学习</div></div></a></div></nav></div><div class="aside-content" id="aside-content"><div class="sticky_layout"><div class="card-widget" id="card-toc"><div class="item-headline"><i class="fas fa-stream"></i><span>目录</span><span class="toc-percentage"></span></div><div class="toc-content"><ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#4-%E5%B8%A6%E6%96%87%E5%AD%97%E7%9A%84%E7%9F%A5%E8%AF%86%E5%9B%BE%E5%B5%8C%E5%85%A5"><span class="toc-number">1.</span> <span class="toc-text">4. 带文字的知识图嵌入</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#4-1-%E5%85%B7%E6%9C%89%E6%96%87%E6%9C%AC%E5%B1%9E%E6%80%A7%E7%9A%84%E6%A8%A1%E5%9E%8B"><span class="toc-number">1.1.</span> <span class="toc-text">4.1 具有文本属性的模型</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#Extended-RESCAL"><span class="toc-number">1.1.0.1.</span> <span class="toc-text">Extended RESCAL</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#Jointly-desp"><span class="toc-number">1.1.0.2.</span> <span class="toc-text">Jointly(desp)</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#DKRL"><span class="toc-number">1.1.0.3.</span> <span class="toc-text">DKRL</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#Jointly"><span class="toc-number">1.1.0.4.</span> <span class="toc-text">Jointly</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#SSP"><span class="toc-number">1.1.0.5.</span> <span class="toc-text">SSP</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#KDCoE"><span class="toc-number">1.1.0.6.</span> <span class="toc-text">KDCoE</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#KGloVe-with-literals"><span class="toc-number">1.1.0.7.</span> <span class="toc-text">KGloVe with literals</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#CATT"><span class="toc-number">1.1.0.8.</span> <span class="toc-text">CATT</span></a><ol class="toc-child"><li class="toc-item toc-level-5"><a class="toc-link" href="#KG%E8%A1%A8%E7%A4%BA"><span class="toc-number">1.1.0.8.1.</span> <span class="toc-text">KG表示</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#%E5%AE%9E%E4%BD%93%E6%8F%8F%E8%BF%B0"><span class="toc-number">1.1.0.8.2.</span> <span class="toc-text">实体描述</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#%E5%AF%B9%E9%BD%90%E6%A8%A1%E5%9E%8B"><span class="toc-number">1.1.0.8.3.</span> <span class="toc-text">对齐模型</span></a></li></ol></li><li class="toc-item toc-level-4"><a class="toc-link" href="#textural-association"><span class="toc-number">1.1.0.9.</span> <span class="toc-text">textural association</span></a><ol class="toc-child"><li class="toc-item toc-level-5"><a class="toc-link" href="#WWV"><span class="toc-number">1.1.0.9.1.</span> <span class="toc-text">WWV</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#PE-WWV"><span class="toc-number">1.1.0.9.2.</span> <span class="toc-text">PE-WWV</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#FeatureSum"><span class="toc-number">1.1.0.9.3.</span> <span class="toc-text">FeatureSum</span></a></li></ol></li><li class="toc-item toc-level-4"><a class="toc-link" href="#open-world-extension-for-KGC"><span class="toc-number">1.1.0.10.</span> <span class="toc-text">open-world extension for KGC</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#EDGE"><span class="toc-number">1.1.0.11.</span> <span class="toc-text">EDGE</span></a><ol class="toc-child"><li class="toc-item toc-level-5"><a class="toc-link" href="#%E5%9F%BA%E6%9C%AC%E5%B5%8C%E5%85%A5%E6%A8%A1%E5%9E%8B"><span class="toc-number">1.1.0.11.1.</span> <span class="toc-text">基本嵌入模型</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#%E5%88%86%E5%B1%82-BiLSTM-%E6%9C%80%E5%A4%A7%E6%B1%A0%E5%8C%96%E7%BC%96%E7%A0%81%E5%99%A8"><span class="toc-number">1.1.0.11.2.</span> <span class="toc-text">分层 BiLSTM 最大池化编码器</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#%E7%9F%A5%E8%AF%86%E7%BA%A6%E6%9D%9F%E6%96%B9%E6%B3%95"><span class="toc-number">1.1.0.11.3.</span> <span class="toc-text">知识约束方法</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#%E8%AE%AD%E7%BB%83"><span class="toc-number">1.1.0.11.4.</span> <span class="toc-text">训练</span></a></li></ol></li><li class="toc-item toc-level-4"><a class="toc-link" href="#TransW"><span class="toc-number">1.1.0.12.</span> <span class="toc-text">TransW</span></a></li></ol></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#4-2-%E5%85%B7%E6%9C%89%E6%95%B0%E5%AD%97%E6%96%87%E6%9C%AC%E7%9A%84%E6%A8%A1%E5%9E%8B"><span class="toc-number">1.2.</span> <span class="toc-text">4.2 具有数字文本的模型</span></a></li></ol></li></ol></div></div></div></div></main><footer id="footer"><div id="footer-wrap"><div class="copyright">&copy;2021 - 2022 By ChaoYuan</div></div></footer></div><div id="rightside"><div id="rightside-config-hide"><button id="readmode" type="button" title="阅读模式"><i class="fas fa-book-open"></i></button><button id="darkmode" type="button" title="浅色和深色模式转换"><i class="fas fa-adjust"></i></button><button id="hide-aside-btn" type="button" title="单栏和双栏切换"><i class="fas fa-arrows-alt-h"></i></button></div><div id="rightside-config-show"><button id="rightside_config" type="button" title="设置"><i class="fas fa-cog fa-spin"></i></button><button class="close" id="mobile-toc-button" type="button" title="目录"><i class="fas fa-list-ul"></i></button><button id="go-up" type="button" title="回到顶部"><i class="fas fa-arrow-up"></i></button></div></div><div id="local-search"><div class="search-dialog"><nav class="search-nav"><span class="search-dialog-title">搜索</span><span id="loading-status"></span><button class="search-close-button"><i class="fas fa-times"></i></button></nav><div class="is-center" id="loading-database"><i class="fas fa-spinner fa-pulse"></i><span>  数据库加载中</span></div><div class="search-wrap"><div id="local-search-input"><div class="local-search-box"><input class="local-search-box--input" placeholder="搜索文章" type="text"/></div></div><hr/><div id="local-search-results"></div></div></div><div id="search-mask"></div></div><div><script src="/js/utils.js"></script><script src="/js/main.js"></script><script src="https://cdn.jsdelivr.net/npm/@fancyapps/ui/dist/fancybox.umd.js"></script><script src="/js/search/local-search.js"></script><div class="js-pjax"></div><div class="aplayer no-destroy" data-id="7303803822" data-server="netease" data-type="playlist" data-fixed="true" data-autoplay="true" data-order="random"> </div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/aplayer@1/dist/APlayer.min.css" media="print" onload="this.media='all'"><script src="https://cdn.jsdelivr.net/npm/aplayer@1/dist/APlayer.min.js"></script><script src="https://cdn.jsdelivr.net/gh/metowolf/MetingJS@1.2/dist/Meting.min.js"></script><script src="https://cdn.jsdelivr.net/npm/pjax/pjax.min.js"></script><script>let pjaxSelectors = ["head > title","#config-diff","#body-wrap","#rightside-config-hide","#rightside-config-show",".js-pjax"]

var pjax = new Pjax({
  elements: 'a:not([target="_blank"])',
  selectors: pjaxSelectors,
  cacheBust: false,
  analytics: false,
  scrollRestoration: false
})

document.addEventListener('pjax:send', function () {

  // removeEventListener scroll 
  window.tocScrollFn && window.removeEventListener('scroll', window.tocScrollFn)
  window.scrollCollect && window.removeEventListener('scroll', scrollCollect)

  typeof preloader === 'object' && preloader.initLoading()
  document.getElementById('rightside').style.cssText = "opacity: ''; transform: ''"
  
  if (window.aplayers) {
    for (let i = 0; i < window.aplayers.length; i++) {
      if (!window.aplayers[i].options.fixed) {
        window.aplayers[i].destroy()
      }
    }
  }

  typeof typed === 'object' && typed.destroy()

  //reset readmode
  const $bodyClassList = document.body.classList
  $bodyClassList.contains('read-mode') && $bodyClassList.remove('read-mode')

})

document.addEventListener('pjax:complete', function () {
  window.refreshFn()

  document.querySelectorAll('script[data-pjax]').forEach(item => {
    const newScript = document.createElement('script')
    const content = item.text || item.textContent || item.innerHTML || ""
    Array.from(item.attributes).forEach(attr => newScript.setAttribute(attr.name, attr.value))
    newScript.appendChild(document.createTextNode(content))
    item.parentNode.replaceChild(newScript, item)
  })

  GLOBAL_CONFIG.islazyload && window.lazyLoadInstance.update()

  typeof chatBtnFn === 'function' && chatBtnFn()
  typeof panguInit === 'function' && panguInit()

  // google analytics
  typeof gtag === 'function' && gtag('config', '', {'page_path': window.location.pathname});

  // baidu analytics
  typeof _hmt === 'object' && _hmt.push(['_trackPageview',window.location.pathname]);

  typeof loadMeting === 'function' && document.getElementsByClassName('aplayer').length && loadMeting()

  // prismjs
  typeof Prism === 'object' && Prism.highlightAll()

  typeof preloader === 'object' && preloader.endLoading()
})

document.addEventListener('pjax:error', (e) => {
  if (e.request.status === 404) {
    pjax.loadUrl('/404.html')
  }
})</script><script async data-pjax src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script></div></body></html>